# Ollama needs to run as a stanalone app in the host computer
#
# Launch with
#  docker compose -p "openwebui_stack" up -d
#  Without -p option, the stack takes the name of the source folder
# For logs
#  docker logs -f open-webui

services:
  open-webui:
    container_name: open-webui
    image: ghcr.io/open-webui/open-webui:latest
    restart: no

    volumes:
      - /Volumes/Data/development/open-webui/volumes/open-webui:/app/backend/data

    ports:
      - 8080:8080

    environment:
      # Enable debug level for Open-WebUI
      - GLOBAL_LOG_LEVEL=DEBUG
      # Ollama runs as a standalon app in the host computer
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      - WEBUI_SECRET_KEY=

    # Make the host computer available inside the container as host.docker.internal
    #  Because Ollama is installed as standalone app in the host computer,
    #  host.docker.internal is a convenient alias to access the host computer,
    #  instead of specificying host computer IP address.
    #  localhost won't work because it refers to this container, no to the host computer
    extra_hosts:
      - host.docker.internal:host-gateway

    labels:
      # Watchtower will check for updates
      - "com.centurylinklabs.watchtower.enable=true"
